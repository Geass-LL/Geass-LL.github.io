---
layout: post
title: "linux 内存管理"
category: kernel
date: 2023-12-04 08:00 +0800
---

内核版本：4.19.289

## 1 LRU算法

参考：<https://www.ctyun.cn/zhishi/p-158284>

### 1.1 LRU链表

每个内存节点会包含以下的LRU链表。LRU、伙伴系统针对的是物理内存。

```c
enum lru_list {
	LRU_INACTIVE_ANON = LRU_BASE,
	LRU_ACTIVE_ANON = LRU_BASE + LRU_ACTIVE,
	LRU_INACTIVE_FILE = LRU_BASE + LRU_FILE,
	LRU_ACTIVE_FILE = LRU_BASE + LRU_FILE + LRU_ACTIVE,
	LRU_UNEVICTABLE,
	NR_LRU_LISTS
};
```

### 1.2 最简化版的LRU链表

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-simple.png)

新页面会被添加到活跃链表头，随着老化过程，会被移到不活跃链表头，再移动到链表尾，最后被移除，或者重新添加到活跃Lru链表。

加入lru：lru_cache_add。

### 1.3 二次机会法

核心思想： 在链表尾置换页面时，检查页面的访问位，访问位为0，就淘汰；访问位为1，就给它第二次机会同时将访问位清零;如果该页面被再次访问，访问位会置1，这样被频繁使用的页面，访问位总是1，就不会被淘汰。

linux使用PG_active和PG_referenced两个标志位来实现第二次机会法；

* PG_active：表示处于活跃链表；
* PG_referenced：软件记录访问标记(实际硬件访问标记从页表的PTE_YOUNG获取)

#### （1）LRU的原始状态

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-1.png)

#### （2）新分配一个匿名页，PG_refereced为0

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-2.png)

#### （3）访问匿名页

访问活跃链表的匿名页会将PG_referenced修改为1。

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-3.png)

访问不活跃链表的匿名页也会将PG_referenced修改为1。

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-4.png)

如果不活跃链表的匿名页PG_referenced已经为1，则修改为0，页面移到活跃链表。

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-5.png)

#### （4）淘汰页面

注意，从尾部开始遍历不活跃链表，如果PG_referenced为1，则修改为0。如果已经为0,那么淘汰。

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-6.png)

#### （5）页面老化：活跃链表迁移到不活跃链表

活跃链表尾部，如果PG_referenced为0，则迁移到不活跃链表。

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-7.png)

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-8.png)

#### 状态转换图

![img](https://github.com/Geass-LL/draw/raw/master/github-io/lru-second-chance-9.png)

## 2 rmap

参考：<https://www.cnblogs.com/LoyenWang/p/12164683.html>

参考：<https://richardweiyang-2.gitbook.io/kernel-exploring/00-index/01-anon_rmap_history>

简单总结：

一个物理页对应存在一个anon_vma，这里的anon_vma实际上是一个树结构，可以通过它查找到多个anon_vma。每个anon_vma可以通过avon_vma_chain再查找到对应的vma。

### 2.1 相关的数据结构

#### anon_vma

anon_vma即匿名类型的vma，vma的类型可以有很多种，在rmap中我们重点关注的是匿名类型的vma。一个物理页通过`struct address_space *mapping`直接关联到anon_vma，基于anon_vma通过anon_vma_chain找到属于该anon_vma的vma。

之所以使用anon_vma而不是直接使用vma，是因为vma是动态的，它们可以分裂、融合。

anon_vma是一个树结构，anon_vma在发生缺页异常、fork进程的时候会创建，调用的函数为：anon_vma_alloc()。

#### vma

进程的虚拟地址区，一个进程会有多个虚拟地址区，这些虚拟地址区可能是文件映射、堆、代码段、数据段等等。通过vma找到anon_vma是简单明了的，直接调用vma->anon_vma即可。

#### anon_vma_chain

由于COW机制，一个anon_vma会和多个进程产生联系，此外，每个子进程又存在自己的anon_vma。情况变得复杂起来了。

anon_vma_chain是anon_vma和vma之间的桥梁。最开始的rmap实现中，anon_vma直接等于一个链表，链接多个vma。由于这种实现方案的内存占用过大，后续的rmap实现进行了优化，引入了anon_vma_chain。

这张图描述的比较好：

![img](https://github.com/Geass-LL/draw/raw/master/github-io/rmap-anon-vma-chain.png)

### 2.2 代码说明

#### fork场景

在fork一个子进程时，不仅会创建子进程自己的anon_vma、vma，还会创建一个anon_vma_chain把子进程的vma和父进程anon_vma建立联系。这样做的原因还是COW，确保物理页通过anon_vma能够同时找到父进程和子进程的vma。

anon_vma_fork()

#### 如何将page和anon_vma建立联系？

```c
/**
 * __page_set_anon_rmap - set up new anonymous rmap
 * @page:	Page to add to rmap	
 * @vma:	VM area to add page to.
 * @address:	User virtual address of the mapping	
 * @exclusive:	the page is exclusively owned by the current process
 */
static void __page_set_anon_rmap(struct page *page,
	struct vm_area_struct *vma, unsigned long address, int exclusive)
{
	struct anon_vma *anon_vma = vma->anon_vma;

	BUG_ON(!anon_vma);

	if (PageAnon(page))
		return;

	/*
	 * If the page isn't exclusively mapped into this vma,
	 * we must use the _oldest_ possible anon_vma for the
	 * page mapping!
	 */
	/* 首次的话，这里会是exclusive=true。*/
	if (!exclusive)
		anon_vma = anon_vma->root;

	anon_vma = (void *) anon_vma + PAGE_MAPPING_ANON;
	page->mapping = (struct address_space *) anon_vma;
	page->index = linear_page_index(vma, address);
}
```

## 3 memcg

## 4 内存分配

### 4.1 伙伴系统

伙伴系统需要考虑反碎片的问题。页分为：不可移动页、可回收页、可移动页三种，相应的有几个迁移类型：

```c
enum migratetype {
	MIGRATE_UNMOVABLE,
	MIGRATE_MOVABLE,
	MIGRATE_RECLAIMABLE,
	MIGRATE_PCPTYPES,	/* the number of types on the pcp lists */
	MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,
#ifdef CONFIG_CMA
	/*
	 * MIGRATE_CMA migration type is designed to mimic the way
	 * ZONE_MOVABLE works.  Only movable pages can be allocated
	 * from MIGRATE_CMA pageblocks and page allocator never
	 * implicitly change migration type of MIGRATE_CMA pageblock.
	 *
	 * The way to use it is to change migratetype of a range of
	 * pageblocks to MIGRATE_CMA which can be done by
	 * __free_pageblock_cma() function.  What is important though
	 * is that a range of pageblocks must be aligned to
	 * MAX_ORDER_NR_PAGES should biggest page be bigger then
	 * a single pageblock.
	 */
	MIGRATE_CMA,
#endif
#ifdef CONFIG_MEMORY_ISOLATION
	MIGRATE_ISOLATE,	/* can't allocate from here */
#endif
	MIGRATE_TYPES
};
```

kswapd只会回收可回收页。

#### 冷热页

冷热页主要优化单页分配，放在CPU的高速缓存中的叫做热页，否则叫做冷页，冷热页是per CPU的。

## 5 内存回收

参考：<https://segmentfault.com/a/1190000020937950>

### 细节问题

#### page_min，page_low，page_high

* 如果空闲页多于pages_high，则内存域的状态是理想的。
* 如果空闲页的数目低于pages_low，则内核开始将页换出到硬盘。
* 如果空闲页的数目低于pages_min，那么页回收工作的压力就比较大，因为内存域中急需空闲页。

#### 为什么lowmem_reserve是一个数组？理论上一个zone一个数字不就够了？

高端内存如果不够用了，可以借用低端内存，但是低端内存不能反过来借用。如果高端内存借得太多，就可能导致低端内存自己无法使用了。

`cat /proc/zoneinfo`获取得到zone DMA的protection: (0, 1643, 15674, 15674, 15674)。

|DMA|DMA32|NORMAL|MOVABLE|DEVICE|
|-|-|-|-|-|
|自己的可以放开用|仅当DMA空闲页大于1643时，可以借给DMA32|仅当空闲也大于15674时，可以借给NORMAL|类似|类似|

所以这个数组实际上对于MOVABLE、DEVICE这种本身就是高端内存的，没什么用，反正不会借出去。这里提到的MOVABLE实际上是一个虚拟内存域，联想到前面伙伴系统提到的迁移类型。

<https://zhuanlan.zhihu.com/p/258560892>


## 一些好的blog

<https://www.cnblogs.com/LoyenWang>
